{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Chris Fryer', 'Los Alamos National Laboratory', 'theoretical', 'astrophysics', 'fluid', 'dynamics', 'computational', 'science', 'high', 'energy', 'density', 'physics', 'nuclear', 'astrophysics'], ['Thomas E Cowan', 'Helmholtz-Zentrum Dresden-Rossendorf', 'laser', 'plasma', 'physics', 'high', 'energy', 'density', 'physics', 'nuclear', 'physics']]\n",
      "[[0.28765798, 0.8972988, -0.5015403, -0.7116809, -0.37641475, 0.6458469, -0.15334713, -0.45366132, 0.023784652, -0.93009734, 0.9012002, -0.053706937, 0.51033497, -0.7116809], [-0.48598468, -0.1815373, 0.65540516, 0.73808175, -0.053706937, 0.023784652, -0.93009734, 0.9012002, -0.053706937, 0.51033497, -0.053706937]]\n"
     ]
    }
   ],
   "source": [
    "db = cluster[\"CGUScholar\"]\n",
    "\n",
    "def get_scholar_profile_from_mongoDB(scholarID_list):\n",
    "    collection_dataList = []\n",
    "    docs = list(db.cguscholar.find({}))\n",
    "\n",
    "    i = 0\n",
    "    for doc in docs:\n",
    "        if i > 10: break\n",
    "        data = []\n",
    "        scholarID_list.append(doc['_id'])\n",
    "        data.append(doc['personalData']['name'])\n",
    "        data.append(doc['personalData']['university'])\n",
    "\n",
    "        for label in (doc['personalData']['label']):\n",
    "            label = label.split(\"_\")\n",
    "\n",
    "            for word in label:\n",
    "                data.append(word)\n",
    "        collection_dataList.append(data)\n",
    "\n",
    "        i = i + 1\n",
    "        #print(\"i:\", i)\n",
    "    return collection_dataList\n",
    "\n",
    "def get_vector(rowData_list):\n",
    "    all_vector = []\n",
    "    for scholar in rowData_list:\n",
    "        vector = []\n",
    "        for word in scholar:\n",
    "            vector.append(model.wv.get_vector(word)[0])\n",
    "        all_vector.append(vector)\n",
    "    return all_vector\n",
    "\n",
    "scholarID_list = []\n",
    "rowData_list = get_scholar_profile_from_mongoDB(scholarID_list)\n",
    "print(rowData_list)\n",
    "\n",
    "rowData = pd.DataFrame(rowData_list)\n",
    "rowData.insert(0, \"ID\", scholarID_list, True)\n",
    "#print(rowData)\n",
    "\n",
    "model = Word2Vec(rowData_list, min_count = 1, vector_size = 1)  # Word2Vec, build_vocab, train\n",
    "model.save(\"test.model\")\n",
    "model.wv.save_word2vec_format('test.txt', binary=False)\n",
    "\n",
    "# get word vector\n",
    "vector = get_vector(rowData_list)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ZZZorWwAAAAJ', 'Chris Fryer', 'Los Alamos National Laboratory', 'theoretical', 'astrophysics', 'fluid', 'dynamics', 'computational', 'science', 'high', 'energy', 'density', 'physics', 'nuclear', 'physics'], ['d-GqKlEAAAAJ', 'Thomas E Cowan', 'Helmholtz-Zentrum Dresden-Rossendorf', 'laser', 'plasma', 'physics', 'high', 'energy', 'density', 'physics', 'nuclear', 'physics']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "df = pd.read_csv('./scholarProfile.csv')\n",
    "data_list = df.values.tolist()\n",
    "def remove_nan_in_list(data_list):\n",
    "    temp = []\n",
    "    result = []\n",
    "    for profile in data_list:\n",
    "        temp = [data for data in profile if str(data) != 'nan']\n",
    "        \n",
    "        result.append(temp)\n",
    "    return result\n",
    "data_list = remove_nan_in_list(data_list)\n",
    "print(data_list)\n",
    "\n",
    "model = Word2Vec(data_list, min_count = 1)  # Word2Vec, build_vocab, train\n",
    "\n",
    "#model = Word2Vec(df_to_list, vector_size = 10, window=15)  # Word2Vec, build_vocab, train\n",
    "model.save(\"test.model\")\n",
    "\n",
    "model.wv.save_word2vec_format('test.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     schoalr_ID            name                            university  \\\n",
      "0  ZZZorWwAAAAJ     Chris Fryer        Los Alamos National Laboratory   \n",
      "1  d-GqKlEAAAAJ  Thomas E Cowan  Helmholtz-Zentrum Dresden-Rossendorf   \n",
      "\n",
      "         label    Unnamed: 4 Unnamed: 5 Unnamed: 6     Unnamed: 7 Unnamed: 8  \\\n",
      "0  theoretical  astrophysics      fluid   dynamics  computational    science   \n",
      "1        laser        plasma    physics       high         energy    density   \n",
      "\n",
      "  Unnamed: 9 Unnamed: 10 Unnamed: 11 Unnamed: 12 Unnamed: 13 Unnamed: 14  \n",
      "0       high      energy     density     physics     nuclear     physics  \n",
      "1    physics     nuclear     physics         NaN         NaN         NaN  \n",
      "[['ZZZorWwAAAAJ', 'Chris Fryer', 'Los Alamos National Laboratory', 'theoretical', 'astrophysics', 'fluid', 'dynamics', 'computational', 'science', 'high', 'energy', 'density', 'physics', 'nuclear', 'physics'], ['d-GqKlEAAAAJ', 'Thomas E Cowan', 'Helmholtz-Zentrum Dresden-Rossendorf', 'laser', 'plasma', 'physics', 'high', 'energy', 'density', 'physics', 'nuclear', 'physics']]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./scholarProfile.csv')\n",
    "print(df)\n",
    "data_list = df.values.tolist()\n",
    "def remove_nan_in_list(data_list):\n",
    "    temp = []\n",
    "    result = []\n",
    "    for profile in data_list:\n",
    "        temp = [data for data in profile if str(data) != 'nan']\n",
    "        result.append(temp)\n",
    "    return result\n",
    "data_list = remove_nan_in_list(data_list)\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('laser plasma physics', 0.17275021970272064),\n",
       " ('d-GqKlEAAAAJ', 0.16694682836532593),\n",
       " ('computational science', 0.11117952316999435),\n",
       " ('Los Alamos National Laboratory', 0.10941315442323685),\n",
       " ('high energy density physics', 0.079634889960289),\n",
       " ('Helmholtz-Zentrum Dresden-Rossendorf', 0.04132020100951195),\n",
       " ('fluid dynamics', 0.03772975876927376),\n",
       " ('nuclear physics', 0.00831594504415989),\n",
       " ('Thomas E Cowan', -0.005896794609725475),\n",
       " ('ZZZorWwAAAAJ', -0.03030233643949032)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = 'Chris Fryer') #, negative='Thomas E Cowan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./scholarProfile.csv')\n",
    "print((df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'cp950' codec can't decode byte 0xc2 in position 719: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jie\\Desktop\\pyEnv\\counter_env39\\word_embedding\\test.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jie/Desktop/pyEnv/counter_env39/word_embedding/test.ipynb#ch0000010?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mscholarProfile.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m r:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jie/Desktop/pyEnv/counter_env39/word_embedding/test.ipynb#ch0000010?line=3'>4</a>\u001b[0m     csv_reader \u001b[39m=\u001b[39m reader(r)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jie/Desktop/pyEnv/counter_env39/word_embedding/test.ipynb#ch0000010?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m csv_reader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jie/Desktop/pyEnv/counter_env39/word_embedding/test.ipynb#ch0000010?line=5'>6</a>\u001b[0m         \u001b[39mprint\u001b[39m(row)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'cp950' codec can't decode byte 0xc2 in position 719: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "with open('scholarProfile.csv', 'r') as r:\n",
    "    csv_reader = reader(r)\n",
    "    for row in csv_reader:\n",
    "        print(row)\n",
    "    \n",
    "\n",
    "#sentences = SentenceIterator('./scholarProfile.csv') \n",
    "#type(sentences)\n",
    "#model = Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import string\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "# connect mongoDB\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = Word2Vec(LineSentence(\"./data/data2.txt\"),  min_count = 1, vector_size = 1)\n",
    "model.save(\"test.model\")\n",
    "model.wv.save_word2vec_format('vector.txt', binary=False)\n",
    "\n",
    "execute = (time.time() - start_time)/60\n",
    "print(f\"execution time: {round(execute, 2)} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('counter_env39': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f02f8a86cc034383279bb3ceaf22d394065411703332b60a18602ebc8e425c91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
