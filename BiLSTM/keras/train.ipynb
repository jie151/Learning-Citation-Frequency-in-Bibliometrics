{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' 'TULvhq0AAAAJ' '20220515' '4245' '1']\n",
      "['1' 'pYZos38AAAAJ' '20220515' '3998' '1']\n",
      "['1' 'cakwOcQAAAAJ' '20220515' '3676' '1']\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jie\\Desktop\\pyEnv\\counter_env39\\biLSTM\\train.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jie/Desktop/pyEnv/counter_env39/biLSTM/train.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mnext\u001b[39m(g))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jie/Desktop/pyEnv/counter_env39/biLSTM/train.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mnext\u001b[39m(g))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jie/Desktop/pyEnv/counter_env39/biLSTM/train.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mnext\u001b[39;49m(g))\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_arrays_from_file(path, batch_size, each_scholar_vectorLen):\n",
    "    while 1:\n",
    "        f = open(path)\n",
    "        data_batch = []\n",
    "        label_batch = []\n",
    "        for line in f:\n",
    "            tmp = line.split()\n",
    "\n",
    "            label_batch.append(int(tmp[0]))\n",
    "            if len(tmp) > each_scholar_vectorLen + 2:\n",
    "                data = data[0:each_scholar_vectorLen]\n",
    "            else:\n",
    "                data.extend([0]*(each_scholar_vectorLen - len(data) + 2))\n",
    "            data_batch.append(data[2:])\n",
    "\n",
    "            \n",
    "            \n",
    "            yield(y)\n",
    "    f.close\n",
    "g = generate_arrays_from_file(\"dataRecord_vector_2_397.txt\", 1)\n",
    "print(next(g))\n",
    "print(next(g))\n",
    "print(next(g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX: (1, 1, 100),labelX: (1,)\n",
      "trainX: (2, 1, 100),labelX: (2,)\n",
      "trainX: (3, 1, 100),labelX: (3,)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# parameters for LSTM\n",
    "nb_lstm_outputs = 1    # 輸出神經元個數\n",
    "nb_time_steps = 1    # 時間序列的長度\n",
    "nb_input_vectors =  100 # 每個輸入序列的向量維度\n",
    "\n",
    "def generate_arrays_from_file(path, batch_size, each_scholar_vectorLen):\n",
    "    while 1:\n",
    "        f = open(path)\n",
    "        cnt = 0\n",
    "        data_batch = []\n",
    "        label_batch = []\n",
    "        for index, line in enumerate(f):\n",
    "            data = line.split()\n",
    "\n",
    "            label_batch.append(int(data[0]))\n",
    "            # 判斷向量的長度，多的去掉，少的補0\n",
    "            if len(data) > each_scholar_vectorLen + 2:\n",
    "                data = data[0:each_scholar_vectorLen + 2]\n",
    "            else:\n",
    "                data.extend([0]*(each_scholar_vectorLen - len(data) + 2))\n",
    "            data_batch.append(data[2:]) # data[0] : label, data[1] : ID\n",
    "            cnt += 1\n",
    "            if (cnt == batch_size):\n",
    "                cnt = 0\n",
    "                dataset = np.array(data_batch)\n",
    "                dataset = dataset.astype('float32')\n",
    "                # 正規化，使資料值介於[0, 1]\n",
    "                #scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "                #dataset = scaler.fit_transform(dataset)\n",
    "                train = np.reshape(dataset, (dataset.shape[0], 1, dataset.shape[1]))\n",
    "                label = np.array(label_batch)\n",
    "                print(f\"\\nindex: {index} trainX: {train.shape},labelX: {label.shape}\")\n",
    "                yield(train, label)\n",
    "                data_batch = []\n",
    "                label_batch = []\n",
    "        f.close()        \n",
    "\n",
    "# building model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Bidirectional(\n",
    "        LSTM(units=64, return_sequences=True),#LSTM(units=nb_lstm_outputs, return_sequences=True),\n",
    "        input_shape=(nb_time_steps, nb_input_vectors,)\n",
    "    )\n",
    ")\n",
    "model.add(Bidirectional(LSTM(units=32)))\n",
    "\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(nb_lstm_outputs, activation='relu'))\n",
    "\n",
    "# compile:loss, optimizer, metrics\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit_generator(generate_arrays_from_file(\"dataRecord_vector_2_397.txt\", 1, 100), steps_per_epoch=4, epochs=2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.02205160e+07  4.24500000e+03  1.00000000e+00  2.98978877e+00\n",
      "   6.42452955e-01 -7.12157130e-01  1.79953182e+00  6.42616212e-01\n",
      "   4.88736439e+00  3.71095514e+00 -3.72403592e-01  2.31035018e+00\n",
      "  -7.44502783e-01 -7.18392134e-01  1.02630806e+00  2.32723475e+00\n",
      "  -2.95525074e-01  4.63386345e+00  4.48978567e+00  5.02468109e+00\n",
      "   1.24918640e+00 -4.00306404e-01  2.58551002e+00  1.05525458e+00\n",
      "   2.46885598e-01  7.84803107e-02  2.64583254e+00  5.34706306e+00\n",
      "   2.60637939e-01  1.50994849e+00  1.50543916e+00  3.55844522e+00\n",
      "   7.48270893e+00  8.13985109e-01  7.25119472e-01  9.78735864e-01\n",
      "   5.70415735e+00 -6.90134346e-01  1.08077653e-01  4.33313036e+00\n",
      "  -6.83723211e-01  1.10592818e+00  5.70816159e-01  1.27882791e+00\n",
      "   7.76474833e-01  2.94348001e+00  1.09244001e+00  2.08178926e+00\n",
      "   1.32866874e-02  1.13289319e-01  6.75930071e+00  1.70083046e+01\n",
      "   6.23792362e+00  3.70951557e+00  1.34713435e+00 -5.87040126e-01\n",
      "   2.74204230e+00  2.76170349e+00  1.27002325e+01  4.40208226e-01\n",
      "   6.50195026e+00  1.84582686e+00  4.25715828e+00  2.12650752e+00\n",
      "   1.29605560e+01  1.45118868e+00  6.39788926e-01  4.86016178e+00\n",
      "  -4.35160577e-01  2.29574394e+00  9.06921089e-01  7.87822366e-01\n",
      "   5.54220229e-02  5.33040106e-01  2.04877496e+00  1.41547108e+01\n",
      "   3.52120924e+00  8.58823597e-01 -4.97029960e-01  3.28148246e-01\n",
      "   1.24107218e+01  1.36503735e+01 -4.03429493e-02  3.49504495e+00\n",
      "   2.32638950e+01  1.80710945e+01  1.39588919e+01  9.99817073e-01\n",
      "   1.40219619e-02  2.74556931e-02  2.33163428e+00  1.66151752e+01\n",
      "  -3.92949909e-01  1.67817026e-01  2.55710459e+00  5.99104023e+00\n",
      "   9.48855495e+00  1.22779541e+01]\n",
      " [ 2.02205160e+07  3.99800000e+03  1.00000000e+00  2.98978877e+00\n",
      "  -3.14678192e-01  1.51169822e-01  1.34558320e-01  6.42616212e-01\n",
      "   5.06003857e-01  1.14885437e+00  3.07805777e-01  4.88736439e+00\n",
      "   3.71095514e+00  5.66699266e-01  2.31035018e+00 -2.69569248e-01\n",
      "   8.12669992e-01  6.67031229e-01  2.96176046e-01  7.60874689e-01\n",
      "   6.44473076e-01  9.80607927e-01  1.82714552e-01 -3.07411730e-01\n",
      "   5.02468109e+00  4.48978567e+00 -5.59063494e-01 -5.87130785e-01\n",
      "   2.58551002e+00 -7.98108160e-01 -9.13252413e-01  5.34706306e+00\n",
      "   2.64583254e+00  1.71682346e+00  3.78948927e+00  1.22718227e+00\n",
      "   2.58941817e+00  5.60589075e-01 -2.00050652e-01  5.58775246e-01\n",
      "   3.75743937e+00  4.30388488e-02  1.45564765e-01  5.60395420e-01\n",
      "   4.65558395e-02  8.41344893e-01  8.13985109e-01  3.69961858e+00\n",
      "   7.48270893e+00  9.78735864e-01  5.70415735e+00 -3.89738888e-01\n",
      "   2.29605392e-01  4.76953316e+00  1.39015511e-01  1.66691077e+00\n",
      "   6.36046219e+00  4.33313036e+00  2.46769786e+00  3.42616662e-02\n",
      "  -2.33416557e-01  3.26625019e-01  1.90744087e-01  8.06268990e-01\n",
      "   9.09491062e-01 -7.63935268e-01 -4.45177466e-01  1.25623107e+00\n",
      "  -6.28044248e-01  1.54827550e-01  1.23117018e+00  6.23680115e-01\n",
      "  -4.28242475e-01  6.75930071e+00 -8.78172994e-01  7.22633183e-01\n",
      "   8.64946365e-01  3.79500866e-01  1.70083046e+01 -4.18231487e-01\n",
      "   4.90640640e+00  7.13369489e-01 -6.61185265e-01  5.28237782e-02\n",
      "   5.37239408e+00  8.96955609e-01 -1.14163712e-01  4.55405891e-01\n",
      "   2.49983883e+00  1.56371117e+00 -4.25348759e-01  1.27002325e+01\n",
      "   7.27265120e-01  6.14421725e-01  4.66235310e-01  7.31907725e-01\n",
      "  -2.03085512e-01  5.81483960e-01]\n",
      " [ 2.02205160e+07  3.67600000e+03  1.00000000e+00  1.27317393e+00\n",
      "   7.60863960e-01  2.98978877e+00  4.64811862e-01  5.90038419e-01\n",
      "   2.89960682e-01  3.02284312e+00 -2.87139863e-01  2.63098049e+00\n",
      "   4.88736439e+00 -8.18232954e-01  3.71095514e+00 -8.81292149e-02\n",
      "   2.31035018e+00  1.16096079e+00  8.36526990e-01  4.00993061e+00\n",
      "   2.32723475e+00 -4.11164284e-01  1.02715783e-01  8.41571450e-01\n",
      "  -3.32877576e-01  4.48978567e+00  5.02468109e+00 -5.44340372e-01\n",
      "   2.03490400e+00 -1.95083439e-01 -1.82535499e-01  1.13721646e-01\n",
      "   5.34706306e+00  1.68298066e-01  2.64583254e+00 -3.10588568e-01\n",
      "   1.96046919e-01 -5.07500172e-01 -1.69524178e-01  9.89731729e-01\n",
      "   3.69961858e+00  9.97876585e-01  1.61098158e+00  9.78735864e-01\n",
      "   5.70415735e+00  1.89857960e+00  9.73120630e-01  7.25392282e-01\n",
      "   3.37943506e+00  5.92637599e-01  4.76953316e+00  4.33313036e+00\n",
      "   1.25829530e+00  2.93025374e+00  1.19965994e+00  2.03800344e+00\n",
      "   1.44806540e+00 -1.39658228e-01  1.06370103e+00  1.03191233e+00\n",
      "   2.94348001e+00 -4.26347286e-01  1.18391740e+00  9.55500424e-01\n",
      "   2.13892365e+00  6.80861294e-01  4.54635054e-01  6.75930071e+00\n",
      "   1.08301783e+00  3.07130480e+00  5.54113723e-02  1.70083046e+01\n",
      "   5.28174043e-01  8.96955609e-01  5.37239408e+00  1.17779374e+00\n",
      "   9.86206234e-01  3.61092043e+00 -6.23856902e-01 -6.06417000e-01\n",
      "   1.65212023e+00  1.27002325e+01  1.28854454e-01  1.42282152e+00\n",
      "   1.15333641e+00 -9.14555967e-01  8.64915466e+00 -2.05437735e-01\n",
      "   2.11293030e+00 -2.03085512e-01  6.41612172e-01  8.53207767e-01\n",
      "   9.49778378e-01  4.84747082e-01  4.25715828e+00 -2.65014648e-01\n",
      "   9.56288040e-01 -7.50900030e-01]]\n"
     ]
    }
   ],
   "source": [
    "def generate_dataframe(filename, each_scholar_vectorLen):\n",
    "    with open(filename, \"r\") as file:\n",
    "        dataList = []\n",
    "        labelList = []\n",
    "        for index, line in enumerate(file):\n",
    "            if index > 9000:\n",
    "                break\n",
    "            data = line.split()\n",
    "            labelList.append(int(data[0]))\n",
    "            if len(data) > each_scholar_vectorLen + 2:\n",
    "                data = data[2:each_scholar_vectorLen]\n",
    "            else:\n",
    "                data.extend([0]*(each_scholar_vectorLen - len(data) + 2) )\n",
    "                data = data[2:]\n",
    "            dataList.append(data)\n",
    "    \n",
    "    df = pd.DataFrame(dataList)\n",
    "    label_df = pd.DataFrame(labelList)\n",
    "    return df, label_df\n",
    "\n",
    "dataframe, label_df = generate_dataframe(\"./dataRecord_vector_2_397.txt\", 100)\n",
    "\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('counter_env39': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f02f8a86cc034383279bb3ceaf22d394065411703332b60a18602ebc8e425c91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
